{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0a0+649135b\n",
      "Torchvision Version:  0.5.0a0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision/io/_video_opt.py:17: UserWarning: video reader based on ffmpeg c++ ops not available\n",
      "  warnings.warn(\"video reader based on ffmpeg c++ ops not available\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import RetinopathyLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28099 images...\n",
      "> Found 7025 images...\n"
     ]
    }
   ],
   "source": [
    "train_set = RetinopathyLoader(root='./data/',mode='train')\n",
    "train_loader = data.DataLoader(dataset=train_set,batch_size=64,shuffle=True)\n",
    "test_set = RetinopathyLoader(root='./data/',mode='test')\n",
    "test_loader = data.DataLoader(dataset=test_set,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 5\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 64\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train':train_loader,\n",
    "                    'val' : test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.8489 Acc: 0.7312\n",
      "val Loss: 0.7992 Acc: 0.7358\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.7973 Acc: 0.7365\n",
      "val Loss: 0.7852 Acc: 0.7381\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.7806 Acc: 0.7391\n",
      "val Loss: 0.7714 Acc: 0.7392\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.7735 Acc: 0.7394\n",
      "val Loss: 0.7834 Acc: 0.7377\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.7638 Acc: 0.7418\n",
      "val Loss: 0.7640 Acc: 0.7428\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.7600 Acc: 0.7423\n",
      "val Loss: 0.7673 Acc: 0.7426\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.7544 Acc: 0.7447\n",
      "val Loss: 0.7743 Acc: 0.7412\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.7524 Acc: 0.7443\n",
      "val Loss: 0.7589 Acc: 0.7431\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.7483 Acc: 0.7456\n",
      "val Loss: 0.7576 Acc: 0.7436\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.7483 Acc: 0.7455\n",
      "val Loss: 0.7519 Acc: 0.7451\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.7445 Acc: 0.7459\n",
      "val Loss: 0.7698 Acc: 0.7428\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.7440 Acc: 0.7484\n",
      "val Loss: 0.7589 Acc: 0.7439\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.7426 Acc: 0.7469\n",
      "val Loss: 0.7489 Acc: 0.7435\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.7389 Acc: 0.7477\n",
      "val Loss: 0.7488 Acc: 0.7459\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.7374 Acc: 0.7489\n",
      "val Loss: 0.7510 Acc: 0.7452\n",
      "\n",
      "Training complete in 451m 6s\n",
      "Best val Acc: 0.745907\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.8804 Acc: 0.7319\n",
      "val Loss: 0.8580 Acc: 0.7334\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.8634 Acc: 0.7347\n",
      "val Loss: 0.8536 Acc: 0.7335\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.8582 Acc: 0.7348\n",
      "val Loss: 0.8485 Acc: 0.7331\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.8548 Acc: 0.7348\n",
      "val Loss: 0.8513 Acc: 0.7328\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.8492 Acc: 0.7348\n",
      "val Loss: 0.8569 Acc: 0.7302\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.8466 Acc: 0.7351\n",
      "val Loss: 0.8431 Acc: 0.7334\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.8431 Acc: 0.7350\n",
      "val Loss: 0.8473 Acc: 0.7334\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.8414 Acc: 0.7351\n",
      "val Loss: 0.8540 Acc: 0.7331\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.8364 Acc: 0.7345\n",
      "val Loss: 0.8664 Acc: 0.7248\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.8364 Acc: 0.7350\n",
      "val Loss: 0.8475 Acc: 0.7315\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.8332 Acc: 0.7347\n",
      "val Loss: 0.8577 Acc: 0.7285\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.8325 Acc: 0.7351\n",
      "val Loss: 0.8423 Acc: 0.7330\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.8272 Acc: 0.7348\n",
      "val Loss: 0.8426 Acc: 0.7315\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.8216 Acc: 0.7356\n",
      "val Loss: 0.8560 Acc: 0.7334\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.8194 Acc: 0.7358\n",
      "val Loss: 0.8399 Acc: 0.7327\n",
      "\n",
      "Training complete in 297m 32s\n",
      "Best val Acc: 0.733523\n"
     ]
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number \n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(models.resnet50())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
